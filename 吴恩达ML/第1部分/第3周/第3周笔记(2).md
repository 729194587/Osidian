
#### 过拟合(Overfitting)

模型 **在训练集上表现很好，但在测试集上表现差**。
**欠拟合**是模型**对训练数据拟合得不够好**，无法捕捉数据中的规律。
**泛化**指模型 **在未见过的新数据（测试集或真实世界数据）上表现良好的能力**。


#### 解决过拟合

- 收集更多数据
- 特征选择
可以通过减少特征数量来避免严重过拟合
但可能会丢失一些信息。
- **正则化**
缩小一些特征的参数，防止这些特征影响过大导致过拟合。

例如，可以通过添加惩罚项来进行正则化：
$$
J(w) = \frac{1}{2m} \sum_{i=1}^{m} \Big(y^{(i)} - w^T x^{(i)}\Big)^2
$$
加入惩罚项：
$$
J_{\mathrm{reg}}(w) = \frac{1}{2m} \sum_{i=1}^{m} \Big(y^{(i)} - w^T x^{(i)}\Big)^2 + \frac{\lambda}{2} \sum_{j=1}^{n} w_j^2
$$
可以通过给特定的参数添加惩罚项来限制其影响。

λ是正则化系数。
如果正则化系数过小，就会过拟合。
如果正则化系数过大，参数全接近于0，模型相当于直线b，就会欠拟合。

通常不会对b进行正则化。


线性回归的正则化：
```python
def compute_cost_linear_reg(X, y, w, b, lambda_ = 1):
    """
    Computes the cost over all examples
    Args:
      X (ndarray (m,n): Data, m examples with n features
      y (ndarray (m,)): target values
      w (ndarray (n,)): model parameters  
      b (scalar)      : model parameter
      lambda_ (scalar): Controls amount of regularization
    Returns:
      total_cost (scalar):  cost 
    """

    m  = X.shape[0]
    n  = len(w)
    cost = 0.
    for i in range(m):
        f_wb_i = np.dot(X[i], w) + b                                   #(n,)(n,)=scalar, see np.dot
        cost = cost + (f_wb_i - y[i])**2                               #scalar             
    cost = cost / (2 * m)                                              #scalar  
 
    reg_cost = 0
    for j in range(n):
        reg_cost += (w[j]**2)                                          #scalar
    reg_cost = (lambda_/(2*m)) * reg_cost                              #scalar
    
    total_cost = cost + reg_cost                                       #scalar
    return total_cost                                                  #scalar
```

逻辑回归的正则化：
```python
def compute_cost_logistic_reg(X, y, w, b, lambda_ = 1):
    """
    Computes the cost over all examples
    Args:
    Args:
      X (ndarray (m,n): Data, m examples with n features
      y (ndarray (m,)): target values
      w (ndarray (n,)): model parameters  
      b (scalar)      : model parameter
      lambda_ (scalar): Controls amount of regularization
    Returns:
      total_cost (scalar):  cost 
    """

    m,n  = X.shape
    cost = 0.
    for i in range(m):
        z_i = np.dot(X[i], w) + b                                      #(n,)(n,)=scalar, see np.dot
        f_wb_i = sigmoid(z_i)                                          #scalar
        cost +=  -y[i]*np.log(f_wb_i) - (1-y[i])*np.log(1-f_wb_i)      #scalar
             
    cost = cost/m                                                      #scalar

    reg_cost = 0
    for j in range(n):
        reg_cost += (w[j]**2)                                          #scalar
    reg_cost = (lambda_/(2*m)) * reg_cost                              #scalar
    
    total_cost = cost + reg_cost                                       #scalar
    return total_cost                                                  #scalar
```






